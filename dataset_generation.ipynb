{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "PREFIX = \"Using the given Super Mario Bros. Gym environment, give a reward function that \"\n",
    "PREFIX_VARIANTS = [\"encourages\", \"incentivizes\", \"motivates\"]\n",
    "permutations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X Position Rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "mains = [\n",
    "    [\n",
    "        [\"go\", \"move\", \"walk\", \"run\"],\n",
    "        [\"right\", \"forward\", \"to the right\"]\n",
    "    ],\n",
    "    [\n",
    "        [\"travel\", \"reach\"],\n",
    "        [\n",
    "            \"as far as possible\",\n",
    "            \"the end of the level\",\n",
    "            \"the flagpole\",\n",
    "            \"the finish\",\n",
    "            \"the goal\",\n",
    "        ],\n",
    "    ]\n",
    "]\n",
    "codes = [10, 50, 100, 200]\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, *mains[0]):\n",
    "    main = f\"{w[0]} the agent to {w[1]} {w[2]} by rewarding it for increasing its x-position.\"\n",
    "    code = f\"\"\"class XReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(XReward, self).__init__(env)\n",
    "        self._prev_x_pos = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        x_reward = max(info['x_pos'] - self._prev_x_pos, 0)\n",
    "        self._prev_x_pos = info['x_pos']\n",
    "        reward += x_reward\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, *mains[1], codes):\n",
    "    main = f\"{w[0]} the agent to {w[1]} {w[2]} by rewarding it for increasing its x-position.\"\n",
    "    code = f\"\"\"class MaxXReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(MaxXReward, self).__init__(env)\n",
    "        self._prev_x_pos = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        x_reward = max(info['x_pos'] - self._prev_x_pos, 0)\n",
    "        self._prev_x_pos = info['x_pos']\n",
    "        reward += x_reward\n",
    "        if terminated:\n",
    "            reward += info['x_pos'] / {w[3]}\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Rewards and Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372\n"
     ]
    }
   ],
   "source": [
    "mains = [[\"complete\", \"finish\", \"beat\"], [\"the level\", \"the game\", \"the stage\"], [\"as fast as possible\", \"quickly\"]]\n",
    "codes = [0, 1, 10, 20]\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, *mains, codes):\n",
    "    main = f\"{w[0]} the agent to {w[1]} {w[2]} {w[3]} by penalizing it for letting the time tick down{' and rewarding it with the time remaining if the agent completes ' + w[2] if w[4] else ''}.\"\n",
    "    code = (\n",
    "        f\"\"\"class TimeReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(TimeReward, self).__init__(env)\n",
    "        self._current_time = 400\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        time_reward = info[\"time\"] - self._current_time\n",
    "        self._current_time = info[\"time\"]\n",
    "        reward += time_reward\n",
    "        if terminated:\n",
    "            reward += info['time'] / {w[4]}\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "        if w[4] else f\"\"\"class TimePenalty(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(TimePenalty, self).__init__(env)\n",
    "        self._current_time = 400\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        time_penalty = info[\"time\"] - self._current_time\n",
    "        self._current_time = info[\"time\"]\n",
    "        penalty += time_penalty\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    )\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Powerup Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n"
     ]
    }
   ],
   "source": [
    "mains = [\"get\", \"grab\", \"use\", \"utilize\", \"obtain\", \"acquire\", \"pick up\"]\n",
    "codes = [[10, 20, 50, 100], [0, 1]]\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, mains, *codes):\n",
    "    main = f\"{w[0]} the agent to {w[1]} powerups by rewarding the agent when it powers up{' and penalizes the agent when it loses its powerup status' if w[3] else ''}.\"\n",
    "    code = f\"\"\"class PowerupReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(PowerupReward, self).__init__(env)\n",
    "        self._prev_status = \"small\"\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        if self._prev_status == 'small' and info[\"status\"] != 'small':\n",
    "            reward += {w[2]}\n",
    "        elif self._prev_status != 'small' and info[\"status\"] == 'small':\n",
    "            reward -= {w[2]}\n",
    "        self._prev_status = info[\"status\"]\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\" if w[3] else f\"\"\"class PowerupReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(PowerupReward, self).__init__(env)\n",
    "        self._prev_status = \"small\"\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        if self._prev_status == 'small' and info[\"status\"] != 'small':\n",
    "            reward += {w[2]}\n",
    "        self._prev_status = info[\"status\"]\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n"
     ]
    }
   ],
   "source": [
    "mains = [\"maximize\", \"accumulate\", \"go for the most\"]\n",
    "codes = [list(range(30, 51, 5)), list(range(5, 21, 5))]\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, mains, *codes):\n",
    "    main = f\"{w[0]} the agent to {w[1]} points by rewarding it for increasing the score.\"\n",
    "    code = f\"\"\"class HighScoreReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(HighScoreReward, self).__init__(env)\n",
    "        self._current_score = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        reward += (info['score'] - self._current_score) / {w[2]}\n",
    "        self._current_score = info['score']\n",
    "        return state, reward / {w[3]}, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coin Rewards and Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "mains = [\n",
    "        (\"collect\", \"ignore\"),\n",
    "        (\"accumulate\", \"avoid\"),\n",
    "        (\"get\", \"avoid getting\"),\n",
    "        (\"grab\", \"dodge\"),\n",
    "        (\"prioritize\", \"skip\"),\n",
    "    ]\n",
    "codes = list(range(20, 0, 5)) + [-1, 1] + list(range(5, 21, 5))\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, mains, codes):\n",
    "    main = f\"{w[0]} the agent to {w[1][0 if w[2] > 0 else 1]} coins by {'rewarding' if w[2] > 0 else 'penalizing'} it for increasing the coin count.\"\n",
    "    code = f\"\"\"class CoinReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(CoinReward, self).__init__(env)\n",
    "        self._current_coins = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        coin_reward = info[\"coins\"] - self._current_coins\n",
    "        self._current_coins = info[\"coins\"]\n",
    "        reward += coin_reward * {w[2]}\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jump Rewards and Penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "930\n"
     ]
    }
   ],
   "source": [
    "mains = [\n",
    "        (\"higher\", \"lower\"),\n",
    "        (\"more\", \"less\"),\n",
    "        (\"as much as possible\", \"as little as possible\"),\n",
    "        (\"constantly\", \"almost never\"),\n",
    "    ]\n",
    "codes = list(range(-5, 0)) + list(range(1, 6))\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, mains, codes):\n",
    "    main = f\"{w[0]} the agent to jump {w[1][0 if w[2] > 0 else 1]} by {'rewarding' if w[2] > 0 else 'penalizing'} it for increasing its y-position.\"\n",
    "    code = f\"\"\"class JumpReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(JumpReward, self).__init__(env)\n",
    "        self._prev_y_pos = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        y_reward = max({min(0, w[2])}, min(info['y_pos'] - self._prev_y_pos, {max(0, w[2])}))\n",
    "        self._prev_y_pos = info['y_pos']\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065\n"
     ]
    }
   ],
   "source": [
    "mains = [\n",
    "    [\"explore\", \"discover\", \"find\"],\n",
    "    [\"areas\", \"locations\", \"places\"],\n",
    "]\n",
    "codes = list(range(1, 6))\n",
    "\n",
    "for w in itertools.product(PREFIX_VARIANTS, *mains, codes):\n",
    "    main = f\"{w[0]} the agent to {w[1]} new {w[2]} by rewarding it for visiting new (x, y) positions in the level.\"\n",
    "    code = f\"\"\"class ExplorationReward(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ExplorationReward, self).__init__(env)\n",
    "        self._visited = set()\n",
    "\n",
    "    def step(self, action):\n",
    "        state, reward, terminated, truncated, info = self.env.step(action)\n",
    "        x_pos, y_pos = info['x_pos'], info['y_pos']\n",
    "        pos = (x_pos, y_pos)\n",
    "        if pos not in self._visited:\n",
    "            self._visited.add(pos)\n",
    "            reward += {w[3]}\n",
    "        return state, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "    permutations.append((PREFIX + main, code))\n",
    "\n",
    "print(len(permutations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(permutations, columns=[\"Instruction\", \"Code\"])\n",
    "df.to_csv(\"dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
